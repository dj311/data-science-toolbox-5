{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of oracle-and-real-data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "guBl1hnUsmNf",
        "eEJNbwsLpB1s",
        "ifDu6QJSpOmZ",
        "YSiMq5Ck85MO"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "G0qq6bLm4rqh",
        "outputId": "81219b48-e145-45f1-ce7a-56cfa97803bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "cell_type": "code",
      "source": [
        "# If running on Google Colab, only cleverhans needs installation. This can be done via:\n",
        "!pip install cleverhans\n",
        "\n",
        "# If running locally, we've listed (TODO) our dependencies in requirements.txt, so the following\n",
        "# should get everything up and running:\n",
        "# !pip install -r requirements.txt\n",
        "\n",
        "import numpy\n",
        "import keras\n",
        "import pandas\n",
        "import requests\n",
        "import io\n",
        "import zipfile\n",
        "import os\n",
        "import re\n",
        "import cleverhans\n",
        "import tensorflow\n",
        "import seaborn\n",
        "import sklearn\n",
        "\n",
        "from cleverhans.attacks import FastGradientMethod\n",
        "from cleverhans.attacks import CarliniWagnerL2\n",
        "from cleverhans.attacks import SaliencyMapMethod\n",
        "from cleverhans.attacks_tf import jacobian_augmentation\n",
        "from cleverhans.attacks_tf import jacobian_graph\n",
        "from cleverhans.loss import CrossEntropy\n",
        "from cleverhans.train import train\n",
        "from cleverhans.utils_keras import KerasModelWrapper\n",
        "from cleverhans.utils_tf import model_eval\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "numpy.random.seed(0xC0FFEE)\n",
        "tensorflow.set_random_seed(0xC0FFEE)\n",
        "rng = numpy.random.RandomState(0xC0FFEE)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cleverhans\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/a0/f0b4386b719f343c4ed3e13cd7792a7a7a4674566ca9b2b34a09b7424220/cleverhans-3.0.1-py3-none-any.whl (198kB)\n",
            "\u001b[K    100% |████████████████████████████████| 204kB 22.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.3.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.6.0)\n",
            "Collecting mnist~=0.2 (from cleverhans)\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (3.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.14.6)\n",
            "Collecting pycodestyle (from cleverhans)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 21.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.3.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (1.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->cleverhans) (40.8.0)\n",
            "Installing collected packages: mnist, pycodestyle, cleverhans\n",
            "Successfully installed cleverhans-3.0.1 mnist-0.2.2 pycodestyle-2.5.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "guBl1hnUsmNf"
      },
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "GS0WJpSyuQeU"
      },
      "cell_type": "markdown",
      "source": [
        "## Loading data"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "OlTdMqCWus2I"
      },
      "cell_type": "markdown",
      "source": [
        "Run the below code to download a copy of the dataset (if you don't already have it):"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fLKVLsJFurZ5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "response = requests.get(\"http://www.schonlau.net/masquerade/masquerade-data.zip\")\n",
        "\n",
        "dataset_file = io.BytesIO(response.content)\n",
        "\n",
        "zipped_dataset = zipfile.ZipFile(dataset_file)\n",
        "zipped_dataset.extractall('data/masquerade-data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gIA5snRclpjq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://www.schonlau.net/intrusion.html\n",
        "# download Masquerade Data (zip File)\n",
        "\n",
        "import pandas as pd\n",
        "directory = './data/masquerade-data'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3X6tHalTlpkU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sorted_nicely( l ):\n",
        "    \"\"\" Sorts the given iterable in the way that is expected.\n",
        " \n",
        "    Required arguments:\n",
        "    l -- The iterable to be sorted.\n",
        " \n",
        "    \"\"\"\n",
        "    convert = lambda text: int(text) if text.isdigit() else text\n",
        "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
        "    return sorted(l, key = alphanum_key)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FP8_s_WClpkp",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "users = range(1,51)\n",
        "df = pd.DataFrame()\n",
        "\n",
        "for filename in sorted_nicely(os.listdir(directory)):\n",
        "    user = pd.read_csv(os.path.join(directory, filename), header=None)\n",
        "    df = pd.concat([df, user], axis = 1)\n",
        "    \n",
        "df.columns = sorted_nicely(os.listdir(directory))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xOhVC6HazrjI"
      },
      "cell_type": "markdown",
      "source": [
        "We've loaded in the dataset, but need to do a little coercion to get it into the required format. First, we make sure  the values in the dataframe are categorical variables sharing the same data type:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5vklxycDrRYm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "commands = numpy.unique(df)\n",
        "command_dtype = pandas.api.types.CategoricalDtype(commands)\n",
        "\n",
        "for column in df:\n",
        "    df[column] = df[column].astype(command_dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kO_pHxcslplN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labelled, unlabelled = df.head(5000), df.tail(len(df) - 5000)  # ignore unlabeled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ZEH_Lws_op3_"
      },
      "cell_type": "markdown",
      "source": [
        "The dataset contains a list of commands run for each user. Treating this as a timeseries, we perform rolling window sampling in blocks of 100 commands, and summarise the usage over each block."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "co7TNH4XqLYG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rolling_window_command_counts(commands, window_size):\n",
        "    \n",
        "    # Save a copy the name of the series to add again to our output. This will preserve the mapping of\n",
        "    # user identifier to (it's column header in the dataframe it came from), which in\n",
        "    # this case is the user identifier. \n",
        "    user = commands.name\n",
        "\n",
        "    # Convert the single column \"which command was run?\" to a column for each\n",
        "    # command, which says \"was command <x> run?\"\n",
        "    commands = pandas.get_dummies(commands)\n",
        "\n",
        "    # Take a rolling sample of the last 100 commands, then sum each \"was command <x> run?\"\n",
        "    # columns to give a bunch \"command <x> was run <y> times in this window\".\n",
        "    command_counts = commands.rolling(window=window_size).aggregate(numpy.sum)\n",
        "\n",
        "    # Remove the first 100 rows because they contain data from blocks of size < 100.\n",
        "    command_counts = command_counts[window_size-1:]\n",
        "    \n",
        "    # Preserve the user identifier (see top of function) as a new column:\n",
        "    \n",
        "    # First, a nasty hack: https://github.com/pandas-dev/pandas/issues/19136\n",
        "    command_counts = command_counts.rename(columns=str)  \n",
        "    \n",
        "    # Then, add in the user (with an adhoc parser to turn the label into a number)\n",
        "    command_counts['user'] = int(user.replace('User', ''))\n",
        "\n",
        "    return command_counts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tdQxI7iTQNPd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Apply to the entire dataset:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Oiyth5e0pYSq",
        "outputId": "b9d1e6c5-b4dd-4e95-c490-d6ba01febb8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2012
        }
      },
      "cell_type": "code",
      "source": [
        "labelled_dataset = pandas.concat([\n",
        "        rolling_window_command_counts(commands, 100)\n",
        "        for user, commands in labelled.iteritems()\n",
        "    ],\n",
        "    ignore_index=True,  # reset index to go from 0 to 4900\n",
        ")\n",
        "\n",
        "labelled_dataset"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>%backup%</th>\n",
              "      <th>.java_wr</th>\n",
              "      <th>.maker_w</th>\n",
              "      <th>.wrapper</th>\n",
              "      <th>.xinitrc</th>\n",
              "      <th>.xsessio</th>\n",
              "      <th>1.1</th>\n",
              "      <th>1.2</th>\n",
              "      <th>1.3</th>\n",
              "      <th>4Dwm</th>\n",
              "      <th>...</th>\n",
              "      <th>xxx</th>\n",
              "      <th>yacc</th>\n",
              "      <th>ypcat</th>\n",
              "      <th>yppasswd</th>\n",
              "      <th>z</th>\n",
              "      <th>zip</th>\n",
              "      <th>zsh</th>\n",
              "      <th>zubs</th>\n",
              "      <th>zz2</th>\n",
              "      <th>user</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245020</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245021</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245022</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245023</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245024</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245025</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245026</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245027</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245028</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245029</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245030</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245031</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245032</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245033</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245034</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245035</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245036</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245037</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245038</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245039</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245040</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245041</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245042</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245043</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245044</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245045</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245046</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245047</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245048</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245049</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>245050 rows × 857 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        %backup%  .java_wr  .maker_w  .wrapper  .xinitrc  .xsessio  1.1  1.2  \\\n",
              "0            0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "1            0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "2            0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "3            0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "4            0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "5            0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "6            0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "7            0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "8            0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "9            0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "10           0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "11           0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "12           0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "13           0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "14           0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "15           0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "16           0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "17           0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "18           0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "19           0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "20           0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "21           0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "22           0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "23           0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "24           0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "25           0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "26           0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "27           0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "28           0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "29           0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "...          ...       ...       ...       ...       ...       ...  ...  ...   \n",
              "245020       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245021       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245022       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245023       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245024       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245025       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245026       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245027       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245028       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245029       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245030       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245031       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245032       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245033       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245034       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245035       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245036       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245037       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245038       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245039       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245040       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245041       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245042       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245043       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245044       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245045       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245046       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245047       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245048       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "245049       0.0       0.0       0.0       0.0       0.0       0.0  0.0  0.0   \n",
              "\n",
              "        1.3  4Dwm  ...   xxx  yacc  ypcat  yppasswd    z  zip  zsh  zubs  zz2  \\\n",
              "0       0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "1       0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "2       0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "3       0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "4       0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "5       0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "6       0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "7       0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "8       0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "9       0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "10      0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "11      0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "12      0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "13      0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "14      0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "15      0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "16      0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "17      0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "18      0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "19      0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "20      0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "21      0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "22      0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "23      0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "24      0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "25      0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "26      0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "27      0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "28      0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "29      0.0   0.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "...     ...   ...  ...   ...   ...    ...       ...  ...  ...  ...   ...  ...   \n",
              "245020  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245021  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245022  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245023  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245024  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245025  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245026  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245027  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245028  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245029  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245030  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245031  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245032  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245033  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245034  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245035  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245036  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245037  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245038  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245039  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245040  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245041  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245042  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245043  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245044  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245045  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245046  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245047  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245048  0.0   1.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "245049  0.0   2.0  ...   0.0   0.0    0.0       0.0  0.0  0.0  0.0   0.0  0.0   \n",
              "\n",
              "        user  \n",
              "0          1  \n",
              "1          1  \n",
              "2          1  \n",
              "3          1  \n",
              "4          1  \n",
              "5          1  \n",
              "6          1  \n",
              "7          1  \n",
              "8          1  \n",
              "9          1  \n",
              "10         1  \n",
              "11         1  \n",
              "12         1  \n",
              "13         1  \n",
              "14         1  \n",
              "15         1  \n",
              "16         1  \n",
              "17         1  \n",
              "18         1  \n",
              "19         1  \n",
              "20         1  \n",
              "21         1  \n",
              "22         1  \n",
              "23         1  \n",
              "24         1  \n",
              "25         1  \n",
              "26         1  \n",
              "27         1  \n",
              "28         1  \n",
              "29         1  \n",
              "...      ...  \n",
              "245020    50  \n",
              "245021    50  \n",
              "245022    50  \n",
              "245023    50  \n",
              "245024    50  \n",
              "245025    50  \n",
              "245026    50  \n",
              "245027    50  \n",
              "245028    50  \n",
              "245029    50  \n",
              "245030    50  \n",
              "245031    50  \n",
              "245032    50  \n",
              "245033    50  \n",
              "245034    50  \n",
              "245035    50  \n",
              "245036    50  \n",
              "245037    50  \n",
              "245038    50  \n",
              "245039    50  \n",
              "245040    50  \n",
              "245041    50  \n",
              "245042    50  \n",
              "245043    50  \n",
              "245044    50  \n",
              "245045    50  \n",
              "245046    50  \n",
              "245047    50  \n",
              "245048    50  \n",
              "245049    50  \n",
              "\n",
              "[245050 rows x 857 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4teyPJwGobpx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels = labelled_dataset['user'] - 1\n",
        "dataset = labelled_dataset.drop(columns=['user'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HplyOBjLKoPB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels =  keras.utils.to_categorical(labels, num_classes=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "T64W_xRg6Gsx"
      },
      "cell_type": "markdown",
      "source": [
        "Creating the training and testing datasets:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "l9nuQQCDNOVW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "training_data, testing_data, training_labels, testing_labels = train_test_split(\n",
        "    dataset,\n",
        "    labels, \n",
        "    test_size=0.10,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eEJNbwsLpB1s"
      },
      "cell_type": "markdown",
      "source": [
        "# Building the Oracle"
      ]
    },
    {
      "metadata": {
        "id": "jhnem8RNQWSs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Following the architecture described in Ryan et al 1998, we create a three-layer backpropagation neural network using Keras."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "f_05tZlK5Gbz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "oracle = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7FnkFt645UHM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_layer = Dense(\n",
        "    units=856,\n",
        "    activation='relu',\n",
        "    input_dim=856,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lBbvmT7PDKJ3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hidden_layer = Dense(\n",
        "    units=30,\n",
        "    activation='relu',\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "StOQDCqqDM8r",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_layer = Dense(\n",
        "    units=50,\n",
        "    activation='softmax',\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oOEnF-QFDkfr",
        "outputId": "ad11c5ff-9322-445f-8136-bf1a462f0bde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "oracle.add(input_layer)\n",
        "oracle.add(hidden_layer)\n",
        "oracle.add(output_layer)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FhIt-t3UD0Dw",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "oracle.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'],\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ifDu6QJSpOmZ"
      },
      "cell_type": "markdown",
      "source": [
        "# Training Oracle on Dataset"
      ]
    },
    {
      "metadata": {
        "id": "imoKqfKzQlai",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we train the neural network intrusion detection system:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "EQlU0zeXLjzw",
        "outputId": "703a984b-c628-425d-8905-739d949f18c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "cell_type": "code",
      "source": [
        "history = oracle.fit(training_data,  training_labels, epochs=3, batch_size=50, validation_data = (testing_data, testing_labels), shuffle=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 220545 samples, validate on 24505 samples\n",
            "Epoch 1/3\n",
            "220545/220545 [==============================] - 80s 365us/step - loss: 0.1845 - acc: 0.9469 - val_loss: 0.0677 - val_acc: 0.9771\n",
            "Epoch 2/3\n",
            "220545/220545 [==============================] - 77s 349us/step - loss: 0.0643 - acc: 0.9780 - val_loss: 0.0468 - val_acc: 0.9822\n",
            "Epoch 3/3\n",
            "220545/220545 [==============================] - 75s 342us/step - loss: 0.0610 - acc: 0.9819 - val_loss: 0.0378 - val_acc: 0.9858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2XhEnbRaQ62s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The trainingn ends with 98.58% accuracy against the test set. Here, we plot it's accuracy over time:"
      ]
    },
    {
      "metadata": {
        "id": "kBgpjHitQ4pi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "outputId": "ca21dc49-f1f0-471c-f8a5-584fa0e87b93"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAFnCAYAAAChL+DqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlTsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Nh6yX-0H2rbe"
      },
      "cell_type": "markdown",
      "source": [
        "# Building a Substitute Model\n",
        "First, mirror the architecture of the oracle:\n",
        "    "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NlBfPzFMSslC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "substitute = Sequential()\n",
        "\n",
        "input_layer = Dense(\n",
        "    units=856,\n",
        "    activation='relu',\n",
        "    input_dim=856,\n",
        ")\n",
        "hidden_layer = Dense(\n",
        "    units=30,\n",
        "    activation='relu',\n",
        ")\n",
        "output_layer = Dense(\n",
        "    units=50,\n",
        "    activation='softmax',\n",
        ")\n",
        "\n",
        "substitute.add(input_layer)\n",
        "substitute.add(hidden_layer)\n",
        "substitute.add(output_layer)\n",
        "\n",
        "# We need to convert our substitute model into the cleverhans format.\n",
        "substitute = KerasModelWrapper(substitute)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w1SpMeOnVNAl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tensorflow_session = tensorflow.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "qGUtASc8WXht"
      },
      "cell_type": "markdown",
      "source": [
        "We start by giving the adversary a small dataset to bootstrap its search. We give it a random sample of 5% of the original data set. \n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1PQRJpIqWkEE",
        "outputId": "85443418-805f-447c-8c6f-3d468b11d5dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "adversary_training_set, adversary_test_set = train_test_split(\n",
        "    labelled_dataset,\n",
        "    train_size=0.05,\n",
        "    stratify=labelled_dataset['user'],\n",
        ")\n",
        "\n",
        "adversary_training_inputs = adversary_training_set.drop('user', axis='columns')\n",
        "adversary_training_labels = adversary_training_set['user'] - 1  # keras requires 0 based index\n",
        "\n",
        "# For some reason cleverhans doesn't detect a GPU when it runs, but our models at the top using\n",
        "# keras _do_. I think this creates a type mis-match: code running on the GPU uses numpy.float64\n",
        "# whilst the cleverhans stuff runs on the CPU and extects numpy.float32 (or vica versa).\n",
        "adversary_training_inputs = adversary_training_inputs.values.astype(numpy.float32)\n",
        "adversary_training_labels = adversary_training_labels.values"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "g2ixBGzrbVCW"
      },
      "cell_type": "markdown",
      "source": [
        "Define symbolic input placeholders for use in Tensor Flow:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dtn01RpmawNm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "number_of_users = 50\n",
        "number_of_commands = 856\n",
        "\n",
        "input_placeholder = tensorflow.placeholder(\n",
        "    tensorflow.float32,\n",
        "    shape=(None, number_of_commands)\n",
        ")\n",
        "\n",
        "output_placeholder = tensorflow.placeholder(\n",
        "    tensorflow.float32,\n",
        "    shape=(None, number_of_users)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "cqBt04p5byWx"
      },
      "cell_type": "markdown",
      "source": [
        "Get the oracle's predictions for the bootstrap inputs:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tXSbKk1MTlaZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bootstrap_oracle_predictions = oracle.predict(adversary_training_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "AW8OmE7dc7wX"
      },
      "cell_type": "markdown",
      "source": [
        "Train substitute using Jacobian Dataset Augmentation:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "J5GRMMLCneXs",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the predictions and loss of the model, symbolically in TensorFlow (i.e. these variables \n",
        "# point to the result of calculations that haven't been performed yet)\n",
        "\n",
        "substitute_predictions = substitute.get_logits(input_placeholder)\n",
        "substitute_loss = CrossEntropy(substitute, smoothing=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cRko-bZKnbpg",
        "outputId": "a20c7349-4407-4b2c-81c0-fee2b9e6a614",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1322
        }
      },
      "cell_type": "code",
      "source": [
        "# Define the Jacobian symbolically using TensorFlow\n",
        "grads = jacobian_graph(substitute_predictions, input_placeholder, number_of_users)\n",
        "\n",
        "number_of_dataset_augmentation_batches = 5\n",
        "dataset_augmentation_batch_size = 512\n",
        "\n",
        "\n",
        "stepsize = 1  # this is the step-size of the Jacobian augmentation (we are working in ints so use 1).\n",
        "\n",
        "\n",
        "# Train the substitute and augment dataset\n",
        "for batch in range(number_of_dataset_augmentation_batches):\n",
        "    print(\"BATCH #\" + str(batch))\n",
        "    \n",
        "    print(\"Substitute training epoch:\")\n",
        "    train(\n",
        "        tensorflow_session, \n",
        "        substitute_loss,\n",
        "        adversary_training_inputs, \n",
        "        keras.utils.to_categorical(adversary_training_labels, num_classes=50),\n",
        "        init_all=False,\n",
        "        args={\n",
        "            'nb_epochs': 10,\n",
        "            'batch_size': 32,\n",
        "            'learning_rate': 0.001,\n",
        "        },\n",
        "        rng=rng,\n",
        "    )\n",
        "    \n",
        "\n",
        "    # If we are not at last substitute training iteration, augment dataset\n",
        "    in_final_batch = batch == number_of_dataset_augmentation_batches - 1\n",
        "    if not in_final_batch:\n",
        "        print(\"Generating new data points:\")\n",
        "        \n",
        "        # Use Jacobian augmentation to generate new data points:\n",
        "        step_coef = 2 * int(int(batch / 3) != 0) - 1 \n",
        "\n",
        "        augmented_dataset_inputs = jacobian_augmentation(\n",
        "            tensorflow_session, \n",
        "            input_placeholder, \n",
        "            adversary_training_inputs, \n",
        "            adversary_training_labels,\n",
        "            grads,\n",
        "            step_coef * stepsize,\n",
        "            dataset_augmentation_batch_size,\n",
        "        )\n",
        "        new_datapoints = augmented_dataset_inputs[len(adversary_training_inputs):]\n",
        "\n",
        "        # Send the newly generated data points to the oracle, and use its output as their labels:\n",
        "        new_labels = oracle.predict(new_datapoints)\n",
        "\n",
        "        # Use argmax to get the most likely label. This follows the blackbox attack model - the\n",
        "        # substitute shouldn't be able to see exact prediction confidence.\n",
        "        new_labels = numpy.argmax(new_labels, axis=1)\n",
        "\n",
        "        augmented_dataset_labels = numpy.hstack([adversary_training_labels, new_labels])\n",
        "\n",
        "        # Replace dataset and labels with augmented dataset and labels\n",
        "        adversary_training_inputs = augmented_dataset_inputs\n",
        "        adversary_training_labels = augmented_dataset_labels"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BATCH #0\n",
            "Substitute training epoch:\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/cleverhans/compat.py:124: calling softmax_cross_entropy_with_logits_v2_helper (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "dim is deprecated, use axis instead\n",
            "num_devices:  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/cleverhans/utils_tf.py:511: UserWarning: No GPUS, running on CPU\n",
            "  warnings.warn(\"No GPUS, running on CPU\")\n",
            "[INFO 2019-03-18 15:01:45,689 cleverhans] Epoch 0 took 2.0771210193634033 seconds\n",
            "[INFO 2019-03-18 15:01:47,819 cleverhans] Epoch 1 took 1.9393043518066406 seconds\n",
            "[INFO 2019-03-18 15:01:49,957 cleverhans] Epoch 2 took 1.9512372016906738 seconds\n",
            "[INFO 2019-03-18 15:01:51,987 cleverhans] Epoch 3 took 1.8366508483886719 seconds\n",
            "[INFO 2019-03-18 15:01:54,105 cleverhans] Epoch 4 took 1.9322068691253662 seconds\n",
            "[INFO 2019-03-18 15:01:56,228 cleverhans] Epoch 5 took 1.9418976306915283 seconds\n",
            "[INFO 2019-03-18 15:01:58,237 cleverhans] Epoch 6 took 1.8289566040039062 seconds\n",
            "[INFO 2019-03-18 15:02:00,328 cleverhans] Epoch 7 took 1.9082238674163818 seconds\n",
            "[INFO 2019-03-18 15:02:02,449 cleverhans] Epoch 8 took 1.9298672676086426 seconds\n",
            "[INFO 2019-03-18 15:02:04,535 cleverhans] Epoch 9 took 1.903015375137329 seconds\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generating new data points:\n",
            "BATCH #1\n",
            "Substitute training epoch:\n",
            "num_devices:  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO 2019-03-18 15:02:35,025 cleverhans] Epoch 0 took 4.265499114990234 seconds\n",
            "[INFO 2019-03-18 15:02:39,431 cleverhans] Epoch 1 took 3.966740369796753 seconds\n",
            "[INFO 2019-03-18 15:02:44,056 cleverhans] Epoch 2 took 4.188504457473755 seconds\n",
            "[INFO 2019-03-18 15:02:48,267 cleverhans] Epoch 3 took 3.7840728759765625 seconds\n",
            "[INFO 2019-03-18 15:02:52,730 cleverhans] Epoch 4 took 4.039032220840454 seconds\n",
            "[INFO 2019-03-18 15:02:56,880 cleverhans] Epoch 5 took 3.7284364700317383 seconds\n",
            "[INFO 2019-03-18 15:03:01,341 cleverhans] Epoch 6 took 4.043584823608398 seconds\n",
            "[INFO 2019-03-18 15:03:05,763 cleverhans] Epoch 7 took 3.999586343765259 seconds\n",
            "[INFO 2019-03-18 15:03:10,156 cleverhans] Epoch 8 took 3.9749202728271484 seconds\n",
            "[INFO 2019-03-18 15:03:14,257 cleverhans] Epoch 9 took 3.680140733718872 seconds\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generating new data points:\n",
            "BATCH #2\n",
            "Substitute training epoch:\n",
            "num_devices:  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO 2019-03-18 15:04:15,706 cleverhans] Epoch 0 took 8.24474573135376 seconds\n",
            "[INFO 2019-03-18 15:04:24,634 cleverhans] Epoch 1 took 7.891599893569946 seconds\n",
            "[INFO 2019-03-18 15:04:33,035 cleverhans] Epoch 2 took 7.477725505828857 seconds\n",
            "[INFO 2019-03-18 15:04:41,251 cleverhans] Epoch 3 took 7.287150621414185 seconds\n",
            "[INFO 2019-03-18 15:04:49,604 cleverhans] Epoch 4 took 7.430698394775391 seconds\n",
            "[INFO 2019-03-18 15:04:57,749 cleverhans] Epoch 5 took 7.225452661514282 seconds\n",
            "[INFO 2019-03-18 15:05:05,951 cleverhans] Epoch 6 took 7.276463270187378 seconds\n",
            "[INFO 2019-03-18 15:05:14,135 cleverhans] Epoch 7 took 7.269887924194336 seconds\n",
            "[INFO 2019-03-18 15:05:22,527 cleverhans] Epoch 8 took 7.476808071136475 seconds\n",
            "[INFO 2019-03-18 15:05:30,764 cleverhans] Epoch 9 took 7.311864376068115 seconds\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generating new data points:\n",
            "BATCH #3\n",
            "Substitute training epoch:\n",
            "num_devices:  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO 2019-03-18 15:07:34,793 cleverhans] Epoch 0 took 14.901471614837646 seconds\n",
            "[INFO 2019-03-18 15:07:51,840 cleverhans] Epoch 1 took 14.49407696723938 seconds\n",
            "[INFO 2019-03-18 15:08:08,471 cleverhans] Epoch 2 took 14.403213262557983 seconds\n",
            "[INFO 2019-03-18 15:08:25,419 cleverhans] Epoch 3 took 14.680983304977417 seconds\n",
            "[INFO 2019-03-18 15:08:42,529 cleverhans] Epoch 4 took 14.834462642669678 seconds\n",
            "[INFO 2019-03-18 15:08:59,249 cleverhans] Epoch 5 took 14.486370325088501 seconds\n",
            "[INFO 2019-03-18 15:09:16,217 cleverhans] Epoch 6 took 14.714560508728027 seconds\n",
            "[INFO 2019-03-18 15:09:34,247 cleverhans] Epoch 7 took 15.763740301132202 seconds\n",
            "[INFO 2019-03-18 15:09:51,159 cleverhans] Epoch 8 took 14.669629096984863 seconds\n",
            "[INFO 2019-03-18 15:10:08,021 cleverhans] Epoch 9 took 14.600950241088867 seconds\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generating new data points:\n",
            "BATCH #4\n",
            "Substitute training epoch:\n",
            "num_devices:  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO 2019-03-18 15:14:30,727 cleverhans] Epoch 0 took 30.236518621444702 seconds\n",
            "[INFO 2019-03-18 15:15:06,658 cleverhans] Epoch 1 took 30.50296926498413 seconds\n",
            "[INFO 2019-03-18 15:15:42,057 cleverhans] Epoch 2 took 30.665745973587036 seconds\n",
            "[INFO 2019-03-18 15:16:17,731 cleverhans] Epoch 3 took 30.8981831073761 seconds\n",
            "[INFO 2019-03-18 15:16:52,279 cleverhans] Epoch 4 took 29.828441858291626 seconds\n",
            "[INFO 2019-03-18 15:17:27,252 cleverhans] Epoch 5 took 30.225929260253906 seconds\n",
            "[INFO 2019-03-18 15:18:02,750 cleverhans] Epoch 6 took 30.781462907791138 seconds\n",
            "[INFO 2019-03-18 15:18:38,461 cleverhans] Epoch 7 took 30.85584831237793 seconds\n",
            "[INFO 2019-03-18 15:19:13,006 cleverhans] Epoch 8 took 29.808660984039307 seconds\n",
            "[INFO 2019-03-18 15:19:48,363 cleverhans] Epoch 9 took 30.60906195640564 seconds\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "5uGnk1fOTqEX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluating Substitute Model\n",
        "\n",
        "Here we evaluate the substitute against the 95% of the dataset it hasn't seen."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2ACXDjruQtfg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "adversary_test_inputs = adversary_test_set.drop('user', axis='columns')\n",
        "adversary_test_labels = adversary_test_set['user'] - 1  # keras requires 0 based index\n",
        "\n",
        "# For some reason cleverhans doesn't detect a GPU when it runs, but our models at the top using\n",
        "# keras _do_. I think this creates a type mis-match: code running on the GPU uses numpy.float64\n",
        "# whilst the cleverhans stuff runs on the CPU and expects numpy.float32 (or vica versa).\n",
        "adversary_test_inputs = adversary_test_inputs.values.astype(numpy.float32)\n",
        "adversary_test_labels = adversary_test_labels.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QPGuaA-mVBPv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, check its accuracy against the true labels:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xOOplTcKcpNZ",
        "outputId": "ebb24225-04ce-4773-e63c-1970ffea69a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "adversary_test_labels_one_hot = keras.utils.to_categorical(adversary_test_labels, num_classes=50)\n",
        "\n",
        "# Evaluate the substitute model on clean test examples against true labels\n",
        "acc = model_eval(\n",
        "    tensorflow_session, \n",
        "    input_placeholder,\n",
        "    output_placeholder,\n",
        "    substitute_predictions,\n",
        "    adversary_test_inputs,\n",
        "    adversary_test_labels_one_hot,\n",
        "    args={'batch_size': 32}\n",
        ")\n",
        "acc"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.960188661414617"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "8x0v7i-TT8BS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, send this test dataset into the oracle to get its predictions. Then, compare the substitute model's  predictions against those of the oracle. This is important as it allows us to measure how good of an imitation of the oracle our substitute is."
      ]
    },
    {
      "metadata": {
        "id": "LcsqLdLlT5G_",
        "colab_type": "code",
        "outputId": "9b745b7b-f01e-4c45-ab4a-a8b369bb71fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "oracle_predicted_labels = oracle.predict(adversary_test_inputs)\n",
        "\n",
        "# Evaluate the substitute model on clean test examples against oracle's labels\n",
        "acc = model_eval(\n",
        "    tensorflow_session, \n",
        "    input_placeholder,\n",
        "    output_placeholder,\n",
        "    substitute_predictions,\n",
        "    adversary_test_inputs,\n",
        "    oracle_predicted_labels,\n",
        "    args={'batch_size': 32}\n",
        ")\n",
        "acc"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9644627531164357"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "Q8F_S8nNUgKT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As one would hope, the substitute model is better as a replica than it is a predictor."
      ]
    },
    {
      "metadata": {
        "id": "AyW24uVuUplz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Inspecting the Synthetic Dataset"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Fpkj-jxkWvQn"
      },
      "cell_type": "markdown",
      "source": [
        "Just inspecting the generated dataset. Notes:\n",
        "  1. Some of the values are negative!\n",
        "  2. The real dataset has an input range of 0-100. This search technique has found all of them, plus a few on each side.\n",
        "  3. The augmented dataset has just less than 200,000 data points. That's almost as many as were used to train the oracle."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "t8HgM1JXTxzj",
        "outputId": "91ce6656-e7c8-4f09-c27a-65dd9332d4a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "numpy.unique(adversary_training_inputs)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ -4.,  -3.,  -2.,  -1.,   0.,   1.,   2.,   3.,   4.,   5.,   6.,\n",
              "         7.,   8.,   9.,  10.,  11.,  12.,  13.,  14.,  15.,  16.,  17.,\n",
              "        18.,  19.,  20.,  21.,  22.,  23.,  24.,  25.,  26.,  27.,  28.,\n",
              "        29.,  30.,  31.,  32.,  33.,  34.,  35.,  36.,  37.,  38.,  39.,\n",
              "        40.,  41.,  42.,  43.,  44.,  45.,  46.,  47.,  48.,  49.,  50.,\n",
              "        51.,  52.,  53.,  54.,  55.,  56.,  57.,  58.,  59.,  60.,  61.,\n",
              "        62.,  63.,  64.,  65.,  66.,  67.,  68.,  69.,  70.,  71.,  72.,\n",
              "        73.,  74.,  75.,  76.,  77.,  78.,  79.,  80.,  81.,  82.,  83.,\n",
              "        84.,  85.,  86.,  87.,  88.,  89.,  90.,  91.,  92.,  93.,  94.,\n",
              "        95.,  96.,  97.,  98.,  99., 100., 101.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "qS3LcfujWlvM"
      },
      "cell_type": "markdown",
      "source": [
        "# Crafting Adversarial Examples\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "m5_76KnirHTB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_command_vector(command_vector, danger=False):\n",
        "    # reshape into a rectangle, and pad slightly beforehand\n",
        "    rectangle_array= numpy.concatenate([command_vector, numpy.array([0,0])]).reshape((26,33))\n",
        "    normalized_array = sklearn.preprocessing.normalize(rectangle_array)\n",
        "    \n",
        "    color = 'Reds' if danger else 'Greens'\n",
        "    \n",
        "    return seaborn.heatmap(\n",
        "        normalized_array,\n",
        "        square=True,\n",
        "        xticklabels=False,\n",
        "        yticklabels=False,\n",
        "        vmin=0, \n",
        "        vmax=1,\n",
        "        cmap=color,\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TzOmrmaTbgut",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Fast Gradient Sign Method\n",
        "\n",
        "Build an attack using the Fast Gradient Sign method. Then generate untargeted adversarial examples for each value in our test set."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "EziI1AYUcqk_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initialize the Fast Gradient Sign Method (FGSM) attack object.\n",
        "fgsm_par = {'eps': 1., 'ord': numpy.inf, 'clip_min': 0., 'clip_max': 100.}\n",
        "fgsm = FastGradientMethod(substitute, sess=tensorflow_session)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uuP-pUO4cr4b",
        "outputId": "9cfd74ac-485b-42d0-87e0-c9893704ae4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "# Craft adversarial examples using the substitute\n",
        "eval_params = {'batch_size': dataset_augmentation_batch_size}\n",
        "x_adv_sub = fgsm.generate(input_placeholder, **fgsm_par)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/cleverhans/attacks/__init__.py:283: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xwDuDMCDC9AY",
        "colab_type": "code",
        "outputId": "ec424deb-436d-4084-a673-74fc29941f57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_adv_sub"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Identity:0' shape=(?, 856) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "uxwrvuwCC9Ae",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "oracle_keras = KerasModelWrapper(oracle)\n",
        "oracle_fgsm_pred = oracle_keras.get_logits(x_adv_sub)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ViBivzAMC9Ap",
        "colab_type": "code",
        "outputId": "1dc21814-d741-4f17-8cab-fb3796d41bbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "oracle_fgsm_pred"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'model_2/dense_3/BiasAdd:0' shape=(?, 50) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "3WionbZaYHcd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using the cleverhans model_eval function, we can see how good our attack is at fooling the oracle, in general. Because the score for accuray is low, the attack has successfully made the oracle misclassify inputs - in 98% of cases."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZKJui3cVctC5",
        "outputId": "0dfc278c-46b8-4f55-f9c6-7df22b3de6a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Evaluate the accuracy of the \"black-box\" model on adversarial examples\n",
        "accuracy = model_eval(\n",
        "        tensorflow_session,\n",
        "        input_placeholder,\n",
        "        output_placeholder,\n",
        "        oracle_fgsm_pred,\n",
        "        adversary_test_inputs,\n",
        "        adversary_test_labels_one_hot,\n",
        "        args=eval_params\n",
        ")\n",
        "print('Test accuracy of oracle on adversarial examples generated '\n",
        "    'using the substitute: ' + str(accuracy))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy of oracle on adversarial examples generated using the substitute: 0.01585065163790067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CC9zxfxrC9A9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is an example of an untargeted attack: we are trying to get the oracle to misclassify activity from a genuine user. "
      ]
    },
    {
      "metadata": {
        "id": "9RTbGaCxC9A_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Targetting Particular Users\n"
      ]
    },
    {
      "metadata": {
        "id": "ihlyeUfXNqNn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We define a function below to take in one particular command vector, and perform a targeted attack against each of the users."
      ]
    },
    {
      "metadata": {
        "id": "wBmYQjCowOFh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_targeted_attack_against_all_users(command_vector, label, attack, attack_params):\n",
        "    \"\"\"\n",
        "    Runs a targeted attack for the given sample against. For each user, we attempt to generate a\n",
        "    similar command vector to the original, which is classified as that user.\n",
        "    \n",
        "    The command prints a summary of the results to stdout, then returns a dataframe containing, \n",
        "    for each attack:\n",
        "      - the original user\n",
        "      - the targeted user\n",
        "      - the oracle models prediction against the adversarial example\n",
        "      - the oracles certainty of that prediction\n",
        "    \"\"\"    \n",
        "    \n",
        "    # Since we run this once against all users, make 50 replicas of the command vector, and\n",
        "    # original label:\n",
        "    original_label_one_hot = keras.utils.to_categorical(label, num_classes=50)\n",
        "    original_labels = numpy.tile(original_label_one_hot, reps=(50,1))\n",
        "    \n",
        "    original_command_vectors = numpy.tile(command_vector, reps=(50, 1))\n",
        "    \n",
        "    # Our target labels are the one-hot-encoded values 0, 1, 2, ..., 49:\n",
        "    target_labels = keras.utils.to_categorical(range(50), num_classes=50)\n",
        "\n",
        "    attack_params['y_target'] = target_labels\n",
        "    \n",
        "    # Apply the attack, generating the adversarial examples:\n",
        "    adversarial_examples = attack.generate_np(\n",
        "        original_command_vectors,\n",
        "        **attack_params,\n",
        "    )\n",
        "\n",
        "    # Stick these examples into the oracle, and find out what classification it gives:\n",
        "    predictions = oracle.predict(adversarial_examples)\n",
        "\n",
        "    # Format the results into a summary dataframe:\n",
        "    original_label = pandas.Series(\n",
        "        numpy.apply_along_axis(numpy.argmax, axis=1, arr=original_labels), # undo one hot encode\n",
        "        name='Original User',\n",
        "    )\n",
        "    target_label = pandas.Series(\n",
        "        numpy.apply_along_axis(numpy.argmax, axis=1, arr=target_labels), # undo one hot encode\n",
        "        name='Target User',\n",
        "    )\n",
        "    predicted_label = pandas.Series(\n",
        "        numpy.apply_along_axis(numpy.argmax, axis=1, arr=predictions),  # undo one hot encode\n",
        "        name='Oracle Prediction',\n",
        "    )\n",
        "    prediction_certainty = pandas.Series(\n",
        "        numpy.apply_along_axis(numpy.max, axis=1, arr=predictions),\n",
        "        name='Oracle Certainty',\n",
        "    )\n",
        "\n",
        "    summary = pandas.concat(\n",
        "        [\n",
        "            original_label,\n",
        "            target_label,\n",
        "            predicted_label,\n",
        "            prediction_certainty,\n",
        "        ],\n",
        "        axis='columns',\n",
        "    )\n",
        "    \n",
        "    # Count the number of targeted attacks which were succcessful:\n",
        "    successful_attacks = summary.apply(lambda row: row[1] == row[2], axis='columns').sum()\n",
        "    \n",
        "    # Don't count  the original_user -> original_user attack:\n",
        "    successful_attacks -= 1 \n",
        "    total_attacks = 49\n",
        "    \n",
        "    # Print out a little message to say how we did :)\n",
        "    print(\n",
        "        \"A targeted attack was successful against {}/{} users (with the given input):\"\n",
        "        .format(successful_attacks, total_attacks)\n",
        "    )\n",
        "\n",
        "    return summary, adversarial_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B0QEFE1qMqVu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For example, below we take a command vector not yet seen by the substitute model and try to craft adversarial examples targeted at each user. As you can see, the attack is relatively unsucessful."
      ]
    },
    {
      "metadata": {
        "id": "bOi6MhmAMm0c",
        "colab_type": "code",
        "outputId": "ca375171-7e90-4d76-9133-123140e5c647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1635
        }
      },
      "cell_type": "code",
      "source": [
        "summary, adversarial_examples = run_targeted_attack_against_all_users(\n",
        "    adversary_test_inputs[0],\n",
        "    adversary_test_labels[0],\n",
        "    fgsm_attack,\n",
        "    fgsm_params,\n",
        ")\n",
        "summary"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A targeted attack was successful against 2/49 users (with the given input):\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Original User</th>\n",
              "      <th>Target User</th>\n",
              "      <th>Oracle Prediction</th>\n",
              "      <th>Oracle Certainty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>43</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>45</td>\n",
              "      <td>0.999998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43</td>\n",
              "      <td>3</td>\n",
              "      <td>43</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>43</td>\n",
              "      <td>4</td>\n",
              "      <td>45</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>43</td>\n",
              "      <td>5</td>\n",
              "      <td>45</td>\n",
              "      <td>0.999951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>43</td>\n",
              "      <td>6</td>\n",
              "      <td>43</td>\n",
              "      <td>0.999989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>43</td>\n",
              "      <td>7</td>\n",
              "      <td>43</td>\n",
              "      <td>0.659104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>43</td>\n",
              "      <td>8</td>\n",
              "      <td>43</td>\n",
              "      <td>0.999916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>43</td>\n",
              "      <td>9</td>\n",
              "      <td>43</td>\n",
              "      <td>0.999961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>43</td>\n",
              "      <td>10</td>\n",
              "      <td>43</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>43</td>\n",
              "      <td>11</td>\n",
              "      <td>43</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>43</td>\n",
              "      <td>12</td>\n",
              "      <td>45</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>43</td>\n",
              "      <td>13</td>\n",
              "      <td>45</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>43</td>\n",
              "      <td>14</td>\n",
              "      <td>43</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>43</td>\n",
              "      <td>15</td>\n",
              "      <td>43</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>43</td>\n",
              "      <td>16</td>\n",
              "      <td>43</td>\n",
              "      <td>0.999775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>43</td>\n",
              "      <td>17</td>\n",
              "      <td>43</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>43</td>\n",
              "      <td>18</td>\n",
              "      <td>45</td>\n",
              "      <td>0.918841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>43</td>\n",
              "      <td>19</td>\n",
              "      <td>43</td>\n",
              "      <td>0.997597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>43</td>\n",
              "      <td>20</td>\n",
              "      <td>45</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>43</td>\n",
              "      <td>21</td>\n",
              "      <td>45</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>43</td>\n",
              "      <td>22</td>\n",
              "      <td>43</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>43</td>\n",
              "      <td>23</td>\n",
              "      <td>43</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>43</td>\n",
              "      <td>24</td>\n",
              "      <td>43</td>\n",
              "      <td>0.975204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>43</td>\n",
              "      <td>25</td>\n",
              "      <td>43</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>43</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>0.998323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>43</td>\n",
              "      <td>27</td>\n",
              "      <td>45</td>\n",
              "      <td>0.998385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>43</td>\n",
              "      <td>28</td>\n",
              "      <td>45</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>43</td>\n",
              "      <td>29</td>\n",
              "      <td>45</td>\n",
              "      <td>0.999997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>43</td>\n",
              "      <td>30</td>\n",
              "      <td>43</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>43</td>\n",
              "      <td>31</td>\n",
              "      <td>45</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>43</td>\n",
              "      <td>32</td>\n",
              "      <td>45</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>43</td>\n",
              "      <td>33</td>\n",
              "      <td>43</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>43</td>\n",
              "      <td>34</td>\n",
              "      <td>43</td>\n",
              "      <td>0.999525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>43</td>\n",
              "      <td>35</td>\n",
              "      <td>45</td>\n",
              "      <td>0.998986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>43</td>\n",
              "      <td>36</td>\n",
              "      <td>43</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>43</td>\n",
              "      <td>37</td>\n",
              "      <td>43</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>43</td>\n",
              "      <td>38</td>\n",
              "      <td>43</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>43</td>\n",
              "      <td>39</td>\n",
              "      <td>43</td>\n",
              "      <td>0.999988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>43</td>\n",
              "      <td>40</td>\n",
              "      <td>43</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>43</td>\n",
              "      <td>41</td>\n",
              "      <td>45</td>\n",
              "      <td>0.999636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>43</td>\n",
              "      <td>42</td>\n",
              "      <td>43</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>43</td>\n",
              "      <td>44</td>\n",
              "      <td>45</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>43</td>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>43</td>\n",
              "      <td>46</td>\n",
              "      <td>45</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>43</td>\n",
              "      <td>47</td>\n",
              "      <td>43</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>43</td>\n",
              "      <td>48</td>\n",
              "      <td>43</td>\n",
              "      <td>0.999978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>43</td>\n",
              "      <td>49</td>\n",
              "      <td>43</td>\n",
              "      <td>0.911575</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Original User  Target User  Oracle Prediction  Oracle Certainty\n",
              "0              43            0                 43          1.000000\n",
              "1              43            1                 43          1.000000\n",
              "2              43            2                 45          0.999998\n",
              "3              43            3                 43          1.000000\n",
              "4              43            4                 45          1.000000\n",
              "5              43            5                 45          0.999951\n",
              "6              43            6                 43          0.999989\n",
              "7              43            7                 43          0.659104\n",
              "8              43            8                 43          0.999916\n",
              "9              43            9                 43          0.999961\n",
              "10             43           10                 43          1.000000\n",
              "11             43           11                 43          1.000000\n",
              "12             43           12                 45          1.000000\n",
              "13             43           13                 45          1.000000\n",
              "14             43           14                 43          1.000000\n",
              "15             43           15                 43          1.000000\n",
              "16             43           16                 43          0.999775\n",
              "17             43           17                 43          1.000000\n",
              "18             43           18                 45          0.918841\n",
              "19             43           19                 43          0.997597\n",
              "20             43           20                 45          1.000000\n",
              "21             43           21                 45          1.000000\n",
              "22             43           22                 43          1.000000\n",
              "23             43           23                 43          1.000000\n",
              "24             43           24                 43          0.975204\n",
              "25             43           25                 43          1.000000\n",
              "26             43           26                 26          0.998323\n",
              "27             43           27                 45          0.998385\n",
              "28             43           28                 45          1.000000\n",
              "29             43           29                 45          0.999997\n",
              "30             43           30                 43          1.000000\n",
              "31             43           31                 45          1.000000\n",
              "32             43           32                 45          1.000000\n",
              "33             43           33                 43          1.000000\n",
              "34             43           34                 43          0.999525\n",
              "35             43           35                 45          0.998986\n",
              "36             43           36                 43          1.000000\n",
              "37             43           37                 43          1.000000\n",
              "38             43           38                 43          1.000000\n",
              "39             43           39                 43          0.999988\n",
              "40             43           40                 43          1.000000\n",
              "41             43           41                 45          0.999636\n",
              "42             43           42                 43          1.000000\n",
              "43             43           43                 43          1.000000\n",
              "44             43           44                 45          1.000000\n",
              "45             43           45                 45          1.000000\n",
              "46             43           46                 45          1.000000\n",
              "47             43           47                 43          1.000000\n",
              "48             43           48                 43          0.999978\n",
              "49             43           49                 43          0.911575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "mspvKRbob1iV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "afef49cf-d21e-40e3-f26f-34aabd42fa3f"
      },
      "cell_type": "code",
      "source": [
        "plot_command_vector(adversary_test_inputs[0])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbf136fee80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAFDCAYAAACJGFHFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "wURvWArRb2Ws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "73d76507-ce15-41e2-b7d8-c84ab503e11a"
      },
      "cell_type": "code",
      "source": [
        "plot_command_vector(adversarial_examples[0], danger=True)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbf136639b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAFDCAYAAACJGFHFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAMAMkhYAwIz/AyH/V5yChilWAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "EkFQOGwDcHvm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As can be seen in the two plots, the key components i.e. most used commands are left unchanged, whilst FGSM creates background noise to cause the misclassification attempt.. "
      ]
    },
    {
      "metadata": {
        "id": "ADD0NPmjVd5_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Developing a Specialised Attack Method\n",
        "\n",
        "Most adversarial attacks are mounted against image classification networks. They aim to minimise visual difference in their generated examples. Our attack has a different set of requirements:\n",
        "\n",
        "  - The set of commands should perform an equivelant task on the target computer.\n",
        "  - We can append the script with as many commands as we like.\n",
        "  \n",
        "In the section below, we modify the Momentum Iterative Method introduced by Dang et al  (2017) to produce additive perturbations only:"
      ]
    },
    {
      "metadata": {
        "id": "4RG1Zq-uklS4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from cleverhans.attacks import optimize_linear\n",
        "from cleverhans.compat import reduce_sum, reduce_mean, softmax_cross_entropy_with_logits\n",
        "from cleverhans import utils_tf\n",
        "\n",
        "\n",
        "class AdditiveMomentumIterativeMethod(cleverhans.attacks.MomentumIterativeMethod):\n",
        "  \"\"\"\n",
        "  Modifies the The Momentum Iterative Method (Dong et al. 2017) to produce additive\n",
        "  perturbations only.\n",
        "  \n",
        "  If it finds the optimal perturbation to be negative, a random addition is performed instead.\n",
        "  \n",
        "  Original paper link: https://arxiv.org/pdf/1710.06081.pdf\n",
        "  \n",
        "  :param model: cleverhans.model.Model\n",
        "  :param sess: optional tf.Session\n",
        "  :param dtypestr: dtype of the data\n",
        "  :param kwargs: passed through to super constructor\n",
        "  \"\"\"\n",
        "\n",
        "  def generate(self, x, **kwargs):\n",
        "    \"\"\"\n",
        "    Generate symbolic graph for adversarial examples and return.\n",
        "    :param x: The model's symbolic inputs.\n",
        "    :param kwargs: Keyword arguments. See `parse_params` for documentation.\n",
        "    \"\"\"\n",
        "    # Parse and save attack-specific parameters\n",
        "    assert self.parse_params(**kwargs)\n",
        "\n",
        "    asserts = []\n",
        "\n",
        "    # If a data range was specified, check that the input was in that range\n",
        "    if self.clip_min is not None:\n",
        "      asserts.append(utils_tf.assert_greater_equal(x,\n",
        "                                                   tf.cast(self.clip_min,\n",
        "                                                           x.dtype)))\n",
        "\n",
        "    if self.clip_max is not None:\n",
        "      asserts.append(utils_tf.assert_less_equal(x,\n",
        "                                                tf.cast(self.clip_max,\n",
        "                                                        x.dtype)))\n",
        "\n",
        "    # Initialize loop variables\n",
        "    momentum = tf.zeros_like(x)\n",
        "    adv_x = x\n",
        "\n",
        "    # Fix labels to the first model predictions for loss computation\n",
        "    y, _nb_classes = self.get_or_guess_labels(x, kwargs)\n",
        "    y = y / reduce_sum(y, 1, keepdims=True)\n",
        "    targeted = (self.y_target is not None)\n",
        "\n",
        "    def cond(i, _, __):\n",
        "      \"\"\"Iterate until number of iterations completed\"\"\"\n",
        "      return tf.less(i, self.nb_iter)\n",
        "\n",
        "    def body(i, ax, m):\n",
        "      \"\"\"Do a momentum step\"\"\"\n",
        "      logits = self.model.get_logits(ax)\n",
        "      loss = softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "      if targeted:\n",
        "        loss = -loss\n",
        "\n",
        "      # Define gradient of loss wrt input\n",
        "      grad, = tf.gradients(loss, ax)\n",
        "\n",
        "      # Normalize current gradient and add it to the accumulated gradient\n",
        "      red_ind = list(range(1, len(grad.get_shape())))\n",
        "      avoid_zero_div = tf.cast(1e-12, grad.dtype)\n",
        "      grad = grad / tf.maximum(\n",
        "          avoid_zero_div,\n",
        "          reduce_mean(tf.abs(grad), red_ind, keepdims=True))\n",
        "      m = self.decay_factor * m + grad\n",
        "\n",
        "      optimal_perturbation = optimize_linear(m, self.eps_iter, self.ord)\n",
        "      optimal_perturbation = tf.maximum(optimal_perturbation, tf.zeros_like(optimal_perturbation))\n",
        "        \n",
        "      if self.ord == 1:\n",
        "        raise NotImplementedError(\"This attack hasn't been tested for ord=1.\"\n",
        "                                  \"It's not clear that FGM makes a good inner \"\n",
        "                                  \"loop step for iterative optimization since \"\n",
        "                                  \"it updates just one coordinate at a time.\")\n",
        "\n",
        "      # Update and clip adversarial example in current iteration\n",
        "      ax = ax + optimal_perturbation\n",
        "      ax = x + utils_tf.clip_eta(ax - x, self.ord, self.eps)\n",
        "\n",
        "      if self.clip_min is not None and self.clip_max is not None:\n",
        "        ax = utils_tf.clip_by_value(ax, self.clip_min, self.clip_max)\n",
        "\n",
        "      ax = tf.stop_gradient(ax)\n",
        "\n",
        "      return i + 1, ax, m\n",
        "\n",
        "    _, adv_x, _ = tf.while_loop(\n",
        "        cond, body, (tf.zeros([]), adv_x, momentum), back_prop=True,\n",
        "        maximum_iterations=self.nb_iter)\n",
        "\n",
        "    if self.sanity_checks:\n",
        "      with tf.control_dependencies(asserts):\n",
        "        adv_x = tf.identity(adv_x)\n",
        "\n",
        "    return adv_x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ctn1LalQnU4P",
        "colab_type": "code",
        "outputId": "45df8ff4-387d-4b0b-d7a4-3342439e69d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1652
        }
      },
      "cell_type": "code",
      "source": [
        "ami_attack = AdditiveMomentumIterativeMethod(substitute, sess=tensorflow_session)\n",
        "ami_params = {\n",
        "    'eps': 100.0,\n",
        "    'eps_iter': 1.0,\n",
        "    'nb_iter': 100,\n",
        "    'ord': numpy.inf,\n",
        "    'clip_min': 0.0,\n",
        "    'clip_max': 100.0,\n",
        "}\n",
        "\n",
        "summary, adversarial_examples = run_targeted_attack_against_all_users(\n",
        "    adversary_test_inputs[0],\n",
        "    adversary_test_labels[0],\n",
        "    ami_attack,\n",
        "    ami_params,\n",
        ")\n",
        "summary"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO 2019-03-18 15:32:04,048 cleverhans] Constructing new graph for attack AdditiveMomentumIterativeMethod\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A targeted attack was successful against 16/49 users (with the given input):\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Original User</th>\n",
              "      <th>Target User</th>\n",
              "      <th>Oracle Prediction</th>\n",
              "      <th>Oracle Certainty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>43</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>43</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>43</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>43</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>43</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>43</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>43</td>\n",
              "      <td>10</td>\n",
              "      <td>48</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>43</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>43</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>43</td>\n",
              "      <td>13</td>\n",
              "      <td>27</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>43</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>43</td>\n",
              "      <td>15</td>\n",
              "      <td>12</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>43</td>\n",
              "      <td>16</td>\n",
              "      <td>31</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>43</td>\n",
              "      <td>17</td>\n",
              "      <td>45</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>43</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>43</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>43</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>43</td>\n",
              "      <td>21</td>\n",
              "      <td>41</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>43</td>\n",
              "      <td>22</td>\n",
              "      <td>12</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>43</td>\n",
              "      <td>23</td>\n",
              "      <td>48</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>43</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>43</td>\n",
              "      <td>25</td>\n",
              "      <td>41</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>43</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>43</td>\n",
              "      <td>27</td>\n",
              "      <td>12</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>43</td>\n",
              "      <td>28</td>\n",
              "      <td>12</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>43</td>\n",
              "      <td>29</td>\n",
              "      <td>12</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>43</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>43</td>\n",
              "      <td>31</td>\n",
              "      <td>31</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>43</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>43</td>\n",
              "      <td>33</td>\n",
              "      <td>8</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>43</td>\n",
              "      <td>34</td>\n",
              "      <td>27</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>43</td>\n",
              "      <td>35</td>\n",
              "      <td>32</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>43</td>\n",
              "      <td>36</td>\n",
              "      <td>36</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>43</td>\n",
              "      <td>37</td>\n",
              "      <td>12</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>43</td>\n",
              "      <td>38</td>\n",
              "      <td>12</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>43</td>\n",
              "      <td>39</td>\n",
              "      <td>34</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>43</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>43</td>\n",
              "      <td>41</td>\n",
              "      <td>41</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>43</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>43</td>\n",
              "      <td>44</td>\n",
              "      <td>36</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>43</td>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>43</td>\n",
              "      <td>46</td>\n",
              "      <td>8</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>43</td>\n",
              "      <td>47</td>\n",
              "      <td>48</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>43</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>43</td>\n",
              "      <td>49</td>\n",
              "      <td>19</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Original User  Target User  Oracle Prediction  Oracle Certainty\n",
              "0              43            0                 14               1.0\n",
              "1              43            1                  1               1.0\n",
              "2              43            2                  2               1.0\n",
              "3              43            3                  3               1.0\n",
              "4              43            4                  8               1.0\n",
              "5              43            5                  5               1.0\n",
              "6              43            6                  0               1.0\n",
              "7              43            7                 12               1.0\n",
              "8              43            8                 20               1.0\n",
              "9              43            9                  5               1.0\n",
              "10             43           10                 48               1.0\n",
              "11             43           11                 11               1.0\n",
              "12             43           12                 12               1.0\n",
              "13             43           13                 27               1.0\n",
              "14             43           14                 14               1.0\n",
              "15             43           15                 12               1.0\n",
              "16             43           16                 31               1.0\n",
              "17             43           17                 45               1.0\n",
              "18             43           18                 18               1.0\n",
              "19             43           19                 19               1.0\n",
              "20             43           20                 20               1.0\n",
              "21             43           21                 41               1.0\n",
              "22             43           22                 12               1.0\n",
              "23             43           23                 48               1.0\n",
              "24             43           24                 24               1.0\n",
              "25             43           25                 41               1.0\n",
              "26             43           26                 26               1.0\n",
              "27             43           27                 12               1.0\n",
              "28             43           28                 12               1.0\n",
              "29             43           29                 12               1.0\n",
              "30             43           30                  2               1.0\n",
              "31             43           31                 31               1.0\n",
              "32             43           32                 32               1.0\n",
              "33             43           33                  8               1.0\n",
              "34             43           34                 27               1.0\n",
              "35             43           35                 32               1.0\n",
              "36             43           36                 36               1.0\n",
              "37             43           37                 12               1.0\n",
              "38             43           38                 12               1.0\n",
              "39             43           39                 34               1.0\n",
              "40             43           40                  0               1.0\n",
              "41             43           41                 41               1.0\n",
              "42             43           42                  2               1.0\n",
              "43             43           43                  1               1.0\n",
              "44             43           44                 36               1.0\n",
              "45             43           45                  2               1.0\n",
              "46             43           46                  8               1.0\n",
              "47             43           47                 48               1.0\n",
              "48             43           48                 48               1.0\n",
              "49             43           49                 19               1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "9SUkSJc2u67k",
        "colab_type": "code",
        "outputId": "99e6fa49-5521-4d11-8142-ed0474222a84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "plot_command_vector(adversary_test_inputs[0])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbf13a86048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAFDCAYAAACJGFHFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "LlZG6VThu-CL",
        "colab_type": "code",
        "outputId": "0a089fc4-7bc5-4fba-a899-1a3469da2906",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "plot_command_vector(adversarial_examples[0], danger=True)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbf1378ac88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAFDCAYAAACJGFHFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCwAQjf8DXPhZdWd+7sMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "n4LMIjjaMbmb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So our modified method gives much better results for targeted attacks, lets see how it compares for untargeted attacks. We have tried to do this below, but the commented part breaks."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IegvI9jAMaJz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Craft adversarial examples using the substitute\n",
        "x_adv_sub_ami = ami_attack.generate(input_placeholder, **ami_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "aa82c553-24f2-49e0-e5f9-909bbf357f97",
        "id": "CvgUg5w6MaKe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_adv_sub_ami"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Identity_4:0' shape=(?, 856) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6LGNE2HLMaK1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "oracle_ami_test = KerasModelWrapper(oracle)\n",
        "oracle_ami_pred = oracle_ami_test.get_logits(x_adv_sub_ami)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "f4dc7eb2-5861-4e12-d44e-1681d0e4365e",
        "id": "Lvqn-37vMaLB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "adversary_test_labels_one_hot.shape, adversary_test_inputs.shape"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((232798, 50), (232798, 856))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "B9LNGbH5MaLQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # Evaluate the accuracy of the \"black-box\" model on adversarial examples\n",
        "# untargetted_accuracy_ami = model_eval(\n",
        "#         tensorflow_session,\n",
        "#         input_placeholder,\n",
        "#         output_placeholder,\n",
        "#         oracle_ami_pred,\n",
        "#         adversary_test_inputs,\n",
        "#         adversary_test_labels_one_hot,\n",
        "#         args=eval_params\n",
        "# )\n",
        "# print('Test accuracy of oracle on adversarial examples generated '\n",
        "#     'using the substitute: ' + str(accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lg3WsDFbVs0s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# An End-to-End Attack\n",
        "\n",
        "In this section, we use the models and attacks developed above to perform a complete attack on the intrusion detection system.\n",
        "\n",
        "First we define two functions:\n",
        "  1. `script_to_command_vector` :: converts a list of bash commands into a command vector (as if it werre generated by `acct`).\n",
        "  2. `pad_script` :: takes an input script and generats an output script with the same behaviour, but with the command counts specified by command_vector."
      ]
    },
    {
      "metadata": {
        "id": "EY8jUsNCKSxq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def script_to_command_vector(script):\n",
        "    lines = script.split(\"\\n\")  # ['netscape', 'sh ./my-script.sh', ...]\n",
        "    commands = [\n",
        "        line.split(\" \")[0] for line in lines\n",
        "    ]  # ['netscape', 'sh', ...]\n",
        "    \n",
        "    commands = pandas.Series(commands).astype(command_dtype)\n",
        "    commands_one_hot = pandas.get_dummies(commands)\n",
        "    command_counts = commands_one_hot.sum()\n",
        "    \n",
        "    return command_counts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "clLauLU2Wu7O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# For our proof-of-concept, just append --help to turn our commands into no-ops. This won't\n",
        "# actually work for all of these commands, but proves the point.\n",
        "COMMAND_TO_NOOP = {command: command + \" --help\" for command in commands}\n",
        "\n",
        "def pad_script(original_script, target_command_counts):\n",
        "    # First, calculate the command counts of the input script:\n",
        "    original_command_counts = script_to_command_vector(original_script)\n",
        "    \n",
        "    # Find the number of each command we need to pad by:\n",
        "    additional_command_counts = target_command_counts - original_command_counts\n",
        "    \n",
        "    # Loop over additional_command_counts and append no-op commands for each additional\n",
        "    # command needed:\n",
        "    \n",
        "    # TODO: finish this\n",
        "    padded_script = original_script\n",
        "    \n",
        "    return padded_script"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FqrpRkx4Wq1p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def masq(script, target_user):\n",
        "    command_vector = script_to_command_vector(script)\n",
        "    original_command_vectors = numpy.array([command_vector])\n",
        "\n",
        "    target_labels = keras.utils.to_categorical(numpy.array([target_user]), num_classes=50)\n",
        "\n",
        "    attack = FastGradientMethod(substitute, sess=tensorflow_session)\n",
        "    adversarial_examples = attack.generate_np(\n",
        "        original_command_vectors,\n",
        "        y_target=target_labels,\n",
        "        eps=1.0,\n",
        "        ord=numpy.inf,\n",
        "        clip_min=0.0,\n",
        "        clip_max=100.0,\n",
        "    )\n",
        "\n",
        "    predicted_labels = oracle.predict(adversarial_examples)\n",
        "    \n",
        "    adversarial_example = adversarial_examples[0]\n",
        "    predicted_label = numpy.argmax(predicted_labels[0])\n",
        "    \n",
        "    if predicted_label == target_user:\n",
        "        fool = 'We have fooled the model!'\n",
        "    else:\n",
        "        fool = 'We have failed to fool the model... oh dear.'\n",
        "    \n",
        "    print('These are the adversarial example that was generated: \\n')\n",
        "    print(str(adversarial_example))\n",
        "    print('\\n and this is the predicted user: \\n')\n",
        "    print(str(predicted_label))\n",
        "    print('\\n '+fool)\n",
        "\n",
        "\n",
        "masq(\n",
        "    script=\"\"\"\n",
        "        cat\n",
        "        hostname\n",
        "        awk\n",
        "        stty\n",
        "        tset\n",
        "        sh\n",
        "        chmod\n",
        "        chmod\n",
        "        chmod\n",
        "        chmod\n",
        "        news\n",
        "        sh ./my-script.sh\n",
        "        netstat\n",
        "        netscape\n",
        "        netscape\n",
        "        netscape\n",
        "        netscape\n",
        "        netscape\n",
        "        netscape\n",
        "    \"\"\",\n",
        "    target_user=16,    \n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}